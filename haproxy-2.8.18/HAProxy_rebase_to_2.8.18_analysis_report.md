HAProxy Rebase to 2.8.18 for OCP 4.22

Context

**Previous release**: 2.8.10

**Release to rebase to**: [2.8.18](https://www.haproxy.org/bugs/bugs-2.8.18.html)

**Comparison**: [2.8.10-2.8.18](https://www.haproxy.org/bugs/bugs-2.8.10.html)

**Test PR**: https://github.com/openshift/router/pull/718

-----

Critical bugs (1)

  - [BUG/CRITICAL: mjson: fix possible DoS when parsing numbers](https://git.haproxy.org/?p=haproxy-2.8.git;a=commitdiff;h=444144e): fixes DoS vulnerability when parsing JSON numbers with large exponents by replacing O(exp) iterative loop with O(log(exp)) shifts and squares approach.
      - **No risk** as mjson is used for Prometheus metrics export (USE_PROMEX), which is not compiled or enabled in OpenShift router.

-----

Major bugs (7)

  - [BUG/MAJOR: mux-h1: Wake SC to perform 0-copy forwarding in CLOSING state](https://git.haproxy.org/?p=haproxy-2.8.git;a=commitdiff;h=1b53186): fixes connection leaks when zero-copy forwarding is enabled. The stream connector was not woken up for I/O events in CLOSING state, leaving H1 connections blocked indefinitely.
      - **No risk**. Zero-copy forwarding (splice) is not enabled in OpenShift router.

  - [BUG/MAJOR: ocsp: Separate refcount per instance and per store](https://git.haproxy.org/?p=haproxy-2.8.git;a=commitdiff;h=7a5ca2a): fixes OCSP response reference counting by introducing two separate counters.
      - **No risk** as we don't use OCSP auto-update in OpenShift router.

  - [BUG/MAJOR: quic: fix wrong packet building due to already acked frames](https://git.haproxy.org/?p=haproxy-2.8.git;a=commitdiff;h=2d1c69d): prevents packet corruption in QUIC streams.
      - **No risk** as QUIC is not used in OpenShift router.

  - [BUG/MAJOR: quic: reject too large CRYPTO frames](https://git.haproxy.org/?p=haproxy-2.8.git;a=commitdiff;h=c090f34): security fix to prevent oversized CRYPTO frames in QUIC.
      - **No risk** as QUIC is not used in OpenShift router.

  - [BUG/MAJOR: listeners: transfer connection accounting when switching listeners](https://git.haproxy.org/?p=haproxy-2.8.git;a=commitdiff;h=27c07ab): fixes per-listener connection count when using shards with multiple thread groups. Incorrect counts caused HAProxy to stop accepting connections.
      - **No risk**. OpenShift router doesn't use sharded binds or multiple thread groups.

  - [BUG/MAJOR: stream: Force channel analysis on successful synchronous send](https://git.haproxy.org/?p=haproxy-2.8.git;a=commitdiff;h=99eb7ae): fixes streams hanging indefinitely when errors occur during data transmission. Forces channel analysis with CF_WAKE_ONCE flag after synchronous sends.
      - **Low risk**. Important fix affecting all HTTP traffic.

  - [BUG/MAJOR: quic: use ncbmbuf for CRYPTO handling](https://git.haproxy.org/?p=haproxy-2.8.git;a=commitdiff;h=e78271f): fixes QUIC CRYPTO frame handling.
      - **No risk** as QUIC is not used in OpenShift router.

-----

Notable medium bugs (11 out of 128)

All QUIC, HTTP/3, Lua, Prometheus, and non-router features were filtered out.

  - [BUG/MEDIUM: mux-h2: Properly handle connection error during preface sending](https://git.haproxy.org/?p=haproxy-2.8.git;a=commitdiff;h=45edc07): fixes error handling when backend HTTP/2 connections fail during the preface phase (initial connection setup). Before fix, connection errors during preface were not properly handled, causing HAProxy to spin in an infinite loop trying to receive data when the client-side H2 stream was blocked (e.g., by flow control). After fix, properly reports H2C error with REFUSED_STREAM, transitions to error state, and prevents infinite loop.
      - **Low risk**. Affects re-encrypt routes with HTTP/2 enabled (default) and h2c app protocol routes. Prevents router from entering infinite loop when backend HTTP/2 connections fail during initialization (network errors, TCP RST, connection timeout, SSL handshake failures).
  - [BUG/MEDIUM: h1: prevent a crash on HTTP/2 upgrade](https://git.haproxy.org/?p=haproxy-2.8.git;a=commitdiff;h=185cab7): fixes infinite loop when client sends HTTP/2 connection preface on HTTP/1.1 connection, triggering implicit HTTP/2 upgrade. Before fix, h1_process() returned -1 when H1 mux was destroyed during upgrade, causing SSL transport layer to consider connection dead while it was still alive (upgraded to H2). SSL xprt tasklet would keep TASK_RUNNING flag set but return NULL, triggering 100% CPU infinite loop on every successful HTTP/2 upgrade. After fix, h1_process() returns -2 to differentiate "mux destroyed, connection alive" from "both destroyed", allowing proper handling.
      - **Low risk**. Affects SSL-terminated frontends when clients send HTTP/2 preface (PRI * HTTP/2.0\r\n\r\nSM\r\n\r\n) instead of HTTP/1.1 requests. OpenShift router allows implicit HTTP/2 upgrades and uses SSL on fe_sni frontend. Without fix, malicious or misconfigured clients could cause router to enter infinite loop. Fix prevents denial of service from such clients.
  - [BUG/MEDIUM: http-ana: Don't close server connection on read0 in TUNNEL mode](https://git.haproxy.org/?p=haproxy-2.8.git;a=commitdiff;h=7b83b1a): fixes premature server connection closure when server sends EOF (read0) in TUNNEL mode. Before fix, SC_FL_NOHALF flag (set when request fully received) was not cleared when entering TUNNEL mode, causing HAProxy to immediately close server connection on read0 even though client may still have data to send. This broke bidirectional communication. After fix, clears SC_FL_NOHALF when switching to TUNNEL mode, allowing proper half-close handling.
      - **Low risk**. Affects WebSocket (HTTP 101 Switching Protocols) and CONNECT method tunnels. Without fix, server EOF would cause immediate connection closure, breaking active WebSocket connections and CONNECT proxies. Especially visible with HTTP/2 clients (RST_STREAM error, "SD--" in logs). OpenShift router supports WebSocket with 1-hour tunnel timeout (default), commonly used by real-time applications. Fix is critical for WebSocket reliability.
  - [BUG/MEDIUM: http-ana: Report 502 from req analyzer only during rsp forwarding](https://git.haproxy.org/?p=haproxy-2.8.git;a=commitdiff;h=9557a5f): fixes incorrect 502 error reporting when server aborts before sending response. Before fix, request analyzer reported 502 immediately on server abort (SC_FL_SHUT_DONE), even when response not yet started (txn->rsp.msg_state < HTTP_MSG_BODY). This prevented response analyzer from properly handling the error, blocking L7 retries and keep-alive silent closes. After fix, request analyzer only reports 502 if response forwarding already started (msg_state >= HTTP_MSG_BODY and empty response buffer), otherwise defers to response analyzer.
      - **Low risk**. Affects reused keep-alive connections and L7 retry scenarios. When backend closes reused connection before sending response (common race condition), response analyzer can now properly detect SF_SRV_REUSED flag and silently close connection (abort_keep_alive), allowing client to safely retry. Without fix, client would get "502 Bad Gateway/SH" error instead of silent close, preventing transparent retry. Important for connection pooling reliability and proper error handling.
  - [BUG/MEDIUM: mux-h1/mux-h2: Reject upgrades with payload on H2 side only](https://git.haproxy.org/?p=haproxy-2.8.git;a=commitdiff;h=c191815): changes protocol upgrade behavior to allow WebSocket and HTTP CONNECT upgrade requests WITH payload on HTTP/1.1 connections, while continuing to reject them on HTTP/2. Before fix (2.8.10 and earlier, since commit 1d2d77b27 in 2.8.0), ALL protocol upgrade requests with payload were rejected with `501 Not Implemented`, regardless of protocol. This was originally done to support H1-to-H2 upgrades (which convert to CONNECT and cannot carry payload). However, this broke valid HTTP/1.1 upgrade-with-payload scenarios. After fix (2.8.13+), behavior splits by protocol: (1) HTTP/1.1 backend: Upgrades with payload NOW ALLOWED, but backend server must fully consume request payload before returning `101 Switching Protocols`. H1 mux validates request is finished before processing upgrade response. (2) HTTP/2 backend: Upgrades with payload still REJECTED with INTERNAL_ERROR (cannot convert to CONNECT with payload). Removes body check from h1_htx.c, adds payload validation in mux_h1.c and mux_h2.c.
      - **BEHAVIOR CHANGE - Low to Medium risk**. This relaxes a restriction that existed in 2.8.10. OpenShift router supports WebSocket upgrades (HTTP 101 Switching Protocols) and uses HTTP/1.1 for backend connections by default. After upgrading to 2.8.18, WebSocket upgrade requests that include a request payload will be ALLOWED instead of rejected with 501. Impact: (1) Applications that were failing with `501 Not Implemented` for upgrade-with-payload requests will now succeed (if backend properly handles it). (2) Most WebSocket clients send empty upgrade requests (no payload), so impact is limited to edge cases. (3) This aligns with HTTP/1.1 RFC compliance - upgrades with payload are valid per spec. (4) Requires backends to fully consume payload before sending 101 response, which is reasonable per HTTP semantics. This is a fix for overly restrictive behavior, enabling valid HTTP/1.1 upgrade scenarios that were previously blocked.
  - [BUG/MEDIUM: ssl: Crash because of dangling ckch_store reference in a ckch instance](https://git.haproxy.org/?p=haproxy-2.8.git;a=commitdiff;h=1f21378): fixes crash when dynamically updating certificates via CLI after updating CA files. Before fix, when updating CA file via "set ssl ca-file" + "commit ssl ca-file", newly rebuilt certificate instances (ckch_inst) were not added to their parent certificate store's (ckch_store) instance list. Later certificate update via "set ssl cert" + "commit ssl cert" would iterate only over instances in the ckch_store list (missing the orphaned instances), delete the old ckch_store, leaving orphaned instances with dangling pointer to freed memory. Next CA update would crash when accessing the dead ckch_store reference during ckch_inst_rebuild. After fix, properly links new instances to ckch_store list via LIST_APPEND, preventing orphaned instances.
      - **No risk**. Only affects HAProxy CLI runtime certificate management commands ("set ssl ca-file", "set ssl cert", "commit ssl"). OpenShift router does not use CLI for certificate updates - instead regenerates entire configuration and performs graceful HAProxy reload. Router manages certificates by writing new config files, not runtime updates.
  - [BUG/MEDIUM: ssl: take care of second client hello](https://git.haproxy.org/?p=haproxy-2.8.git;a=commitdiff;h=324fd5c): fixes memory leak in ssl-capture pool when a second ClientHello message occurs (e.g., TLS 1.3 HelloRetryRequest). The leak happened when the ClientHello callback was called twice per connection.
      - **No risk**. SSL capture feature (tune.ssl.capture-buffer-size) is not enabled in OpenShift router.
  - [BUG/MEDIUM: ssl: ca-file directory mode must read every certificates of a file](https://git.haproxy.org/?p=haproxy-2.8.git;a=commitdiff;h=09a28e9): fixes incomplete CA certificate loading when ca-file points to a DIRECTORY containing bundle files with multiple certificates. Before fix, when scanning directory files (using scandir), HAProxy used BIO_read_filename + PEM_read_bio_X509_AUX which only reads the FIRST certificate from each file, ignoring remaining CAs in multi-cert bundles. This broke SSL verification for certificates signed by the 2nd, 3rd, etc. CAs in bundle files. After fix, uses X509_STORE_load_locations() on each file which properly loads ALL certificates from bundle files.
      - **No risk**. Only affects ca-file when path is a DIRECTORY (not regular file). OpenShift router uses ca-file with FILES only (/etc/ssl/certs/ca-bundle.trust.crt, /var/lib/haproxy/mtls/latest/ca-bundle.pem), never directories. When ca-file points to a file (not directory), HAProxy already used X509_STORE_load_locations() which loads all certificates correctly. Primary use case is httpclient with @system-ca (system CA directory) and custom CA directories - not used by OpenShift router.
  - [BUG/MEDIUM: ssl/clienthello: ECDSA with ssl-max-ver TLSv1.2 and no ECDSA ciphers](https://git.haproxy.org/?p=haproxy-2.8.git;a=commitdiff;h=11f80a1): fixes incorrect ECDSA certificate selection when client supports TLSv1.3 but server restricts to TLSv1.2. Previous fix (commit 23093c72 for TLSv1.3 ECDSA priority) checked for TLSv1.3 ciphersuites (NID_auth_any) to select ECDSA certificate. Before this fix, when client advertised TLSv1.3 ciphersuites + ECDSA signature algorithms but only RSA ciphers for TLSv1.2, AND server configured "ssl-max-ver TLSv1.2", HAProxy would incorrectly select ECDSA certificate (due to TLSv1.3 ciphersuites in ClientHello), but negotiate TLSv1.2 where client only supports RSA ciphers, causing handshake failure. After fix, only allows ECDSA selection for NID_auth_any (TLSv1.3 ciphersuites) if server allows TLSv1.3 (ssl_methods.max >= CONF_TLSV13).
      - **Low risk**. Only affects configurations with explicit "ssl-max-ver TLSv1.2" restriction AND ECDSA certificates AND clients with mixed TLSv1.3/1.2 cipher capabilities. OpenShift router defaults: ssl-min-ver TLSv1.2, NO ssl-max-ver (allows TLSv1.3), includes ECDHE-ECDSA ciphers for TLSv1.2 in all cipher profiles. Only impacts router if user explicitly sets SSL_MAX_VERSION=TLSv1.2 env var AND removes ECDSA ciphers from TLSv1.2 suite - extremely unlikely scenario.
  - [BUG/MEDIUM: backend: do not overwrite srv dst address on reuse (2)](https://git.haproxy.org/?p=haproxy-2.8.git;a=commitdiff;h=550a704) + [BUG/MEDIUM: backend: fix reuse with set-dst/set-dst-port](https://git.haproxy.org/?p=haproxy-2.8.git;a=commitdiff;h=52a216f): fixes connection reuse bug affecting `set-dst` and `set-dst-port` configurations. Before fix (2.8.10-2.8.14), destination address was only included in connection hash under specific conditions (`!is_addr(&srv->addr) || srv->flags & SRV_F_MAPPORTS`), but was systematically overwritten on EVERY connection (reused or new). This allowed wrong connections to be reused when using `set-dst`/`set-dst-port` with regular (non-transparent) servers - connections with different destination addresses could be reused because dst wasn't in hash, but bug was masked by systematic dst overwrite. After fix (2.8.15+), destination address is ALWAYS included in hash calculation and overwrite only happens on new connections (not reuse), preventing wrong connection reuse.
      - **No risk**. OpenShift router does not use `set-dst` or `set-dst-port` HAProxy directives. These directives are for dynamically changing backend destination addresses based on request content (e.g., Host header routing, HTTP header-based backend selection). OpenShift router uses standard server definitions with fixed addresses resolved from Kubernetes endpoints. Bug only affected configurations explicitly using `http-request set-dst` or `tcp-request content set-dst-port`.
  - [BUG/MEDIUM: check: Set SOCKERR by default when a connection error is reported](https://git.haproxy.org/?p=haproxy-2.8.git;a=commitdiff;h=7f971c6): fixes healthcheck error handling when internal errors occur without proper error flags being set. Before fix (2.8.10-2.8.15), `chk_report_conn_err()` would return early if connection error flags (CO_FL_ERROR, SE_FL_ERROR) were not set and check wasn't expired, even when an actual error occurred. This was problematic when multiplexer allocation fails during healthcheck connection setup - the error occurs but error flags might not be properly set yet. The healthcheck would not be interrupted, potentially hanging indefinitely or leading to crashes. After fix (2.8.16+), removed early return and added fallback: if error is reported but no specific status was determined during processing, defaults to HCHK_STATUS_SOCKERR to ensure healthcheck failure is always properly recorded.
      - **Low risk**. OpenShift router uses TCP healthchecks (`check inter <interval>`) for backend endpoints when multiple endpoints exist. Bug could affect healthcheck reliability under resource exhaustion (memory allocation failures for multiplexer during healthcheck setup), potentially causing backends to be incorrectly marked healthy when they should be down, or router instability. However, multiplexer allocation failures during healthchecks are rare - typically only occur under severe memory pressure. Most healthcheck failures (connection refused, timeout, network errors) properly set error flags and were handled correctly even before fix. This fix improves robustness for edge cases but unlikely to be hit in normal operation.

-----

Notable minor bugs (6 out of 199)

  - [BUG/MINOR: h1: Reject empty coding name as last transfer-encoding value](https://git.haproxy.org/?p=haproxy-2.8.git;a=commitdiff;h=a76e5b3): fixes parsing of Transfer-Encoding headers with trailing commas (e.g., `Transfer-Encoding: chunked,`). Before fix (2.8.10), the empty trailing value after comma was silently ignored - the function would continue parsing and potentially accept malformed headers. After fix (2.8.11+), explicitly checks if next comma is at end of line (`n+1 == e`) and rejects with `400 Bad Request`. This is part of hardening against HTTP request smuggling attacks where attackers use malformed Transfer-Encoding headers to desynchronize frontend/backend interpretation of message boundaries.
      - **Low risk**. Security hardening for HTTP/1.1 request parsing. Prevents potential HTTP request smuggling via malformed Transfer-Encoding headers. OpenShift router processes all HTTP/1.1 client requests and may forward them to HTTP/1.1 backends. Before fix, certain malformed headers like `Transfer-Encoding: chunked,` could be silently accepted when they should be rejected per RFC 7230. No impact on legitimate traffic - well-formed clients never send empty transfer coding values. Fix ensures strict RFC compliance and prevents smuggling attempts.
  - [BUG/MINOR: h1: Fail to parse empty transfer coding names](https://git.haproxy.org/?p=haproxy-2.8.git;a=commitdiff;h=58ee718): fixes parsing of Transfer-Encoding headers with empty values within comma-separated lists (e.g., `Transfer-Encoding: chunked,,gzip`, `,chunked`, or `chunked, ,gzip`). Before fix (2.8.10), empty values were not caught during header parsing - they were later treated as unknown coding names by the H1 multiplexer, which returned `422 Unprocessable Content`. While error was detected, the response code was inaccurate and detection happened too late in processing. After fix (2.8.11+), explicitly checks for empty values (`!word.len`) during parsing and returns `400 Bad Request` immediately. This is the second part of Transfer-Encoding header validation hardening, complementing commit a76e5b3 (trailing comma check).
      - **Low risk**. Security hardening for HTTP/1.1 request parsing. Improves error detection accuracy and ensures early rejection of malformed Transfer-Encoding headers during parsing phase rather than later during multiplexer processing. Part of defense-in-depth against HTTP request smuggling - prevents attackers from using empty transfer coding values to confuse message boundary interpretation. OpenShift router processes all HTTP/1.1 requests, making this validation important. No impact on legitimate traffic - RFC 7230 requires non-empty transfer coding values.
  - [BUG/MINOR: http-ana: Properly detect client abort when forwarding the response](https://git.haproxy.org/?p=haproxy-2.8.git;a=commitdiff;h=734720b): fixes client vs server abort detection in logs.
      - **No risk**. Logging accuracy only.
  - [BUG/MINOR: Don't report early srv aborts on request forwarding in DONE state](https://git.haproxy.org/?p=haproxy-2.8.git;a=commitdiff;h=20aa0af): fixes L7 retry handling when server aborts during request forwarding. Scenario: Request fully processed (HTTP_MSG_DONE state), waiting to be forwarded to server, server aborts before sending response. Before fix (2.8.10-2.8.12), server abort was detected immediately in request analyzer when response buffer was empty, even though response not yet started. This prevented response analyzers from handling the abort, blocking L7 retries from being attempted. After fix (2.8.13+), added check `txn->rsp.msg_state >= HTTP_MSG_BODY` - only report server abort if response analysis already started. Otherwise, defer to response analyzers which can properly handle retries.
      - **Low risk**. Affects L7 retry scenarios and connection reuse when server aborts before sending response. This is complementary to commit 9557a5f (v2.8.15) which handles similar issue in different code path. Before fix, L7 retries could be incorrectly skipped when server aborted early, causing clients to receive errors instead of transparent retry. OpenShift router uses connection pooling (`http-reuse safe` by default), making server aborts on reused connections a common race condition scenario. HAProxy's default retry behavior (retry-on all-retryable-errors) means retries would be attempted if properly detected. Fix ensures response analyzers get chance to handle abort and trigger retry logic when appropriate, improving reliability for intermittent backend failures.
  - [BUG/MINOR: server: Update healthcheck when server settings are changed via CLI](https://git.haproxy.org/?p=haproxy-2.8.git;a=commitdiff;h=2e94ab4): properly updates healthcheck transport layer when SSL or healthcheck settings are changed via CLI.
      - **No risk**. OpenShift router does not use `set server ssl on|off`, `check-addr`, or `check-port` CLI commands for dynamic updates.
  - [BUG/MINOR: mux-h1: Don't pretend connection was released for TCP>H1>H2 upgrade](https://git.haproxy.org/?p=haproxy-2.8.git;a=commitdiff;h=a5c0692): fixes return value in h1_process() during TCP-to-H1-to-H2 protocol upgrade chain. Scenario: TCP connection upgraded to H1, then H2 preface detected triggering second upgrade H1-to-H2. Before fix (2.8.10-2.8.15), when H1 connection was in H1_CS_UPGRADING state during h2 upgrade, h1_process() would set flags, alert stream, but then return -1 (signaling "connection released") even though connection was NOT released yet (waiting for stream connector detachment first). After fix (2.8.16+), returns 0 instead, correctly signaling connection is still alive. Commit author notes bug is "harmless" but incorrect - fixed to prevent potential future issues.
      - **No risk**. OpenShift router does not use TCP mode frontends - all frontends configured as `mode http`. TCP>H1>H2 upgrade chain requires starting with TCP mode frontend, which router doesn't have. Even if scenario occurred, bug was described as harmless by author. This is a correctness fix for internal connection tracking state, not a functional bug affecting traffic.
